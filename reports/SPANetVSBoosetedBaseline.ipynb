{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import awkward as ak\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import vector\n",
    "\n",
    "from coffea.hist.plot import clopper_pearson_interval\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test target file\n",
    "test_file = \"hhh_test.h5\"\n",
    "test_h5 = h5.File(test_file)\n",
    "\n",
    "# read baseline prediction\n",
    "baseline_file = \"pred_baseline.h5\"\n",
    "b_h5 = h5.File(baseline_file)\n",
    "\n",
    "# read spanet prediction\n",
    "spanet_file = \"pred_v53.h5\"\n",
    "s_h5 = h5.File(spanet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_pred_by_dp_ap(dps, aps, bb_ps, dp_cut, ap_cut):\n",
    "    # parse predicted bb assignment by DP\n",
    "    dp_filter = dps > dp_cut\n",
    "    ap_filter = aps > ap_cut\n",
    "    filter = ap_filter & dp_filter\n",
    "    bb_ps_passed = bb_ps.mask[filter]\n",
    "    bb_ps_passed = ak.drop_none(bb_ps_passed)\n",
    "\n",
    "    return bb_ps_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_target_by_mask(bb_ts, bh_pts, bh_masks):\n",
    "    bb_ts_selected = bb_ts.mask[bh_masks]\n",
    "    bb_ts_selected = ak.drop_none(bb_ts_selected)\n",
    "\n",
    "    bh_selected_pts = bh_pts.mask[bh_masks]\n",
    "    bh_selected_pts = ak.drop_none(bh_selected_pts)\n",
    "\n",
    "    return bb_ts_selected, bh_selected_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81791964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pred look up table is in shape\n",
    "# [event,\n",
    "#    pred_H,\n",
    "#       [correct, pred_H_pt]]\n",
    "def gen_pred_LUT(bb_ps_passed, bb_ts_selected, fj_pts):\n",
    "    LUT = []\n",
    "    # for each event\n",
    "    for bb_t_event, bb_p_event, fj_pt_event in zip(\n",
    "        bb_ts_selected, bb_ps_passed, fj_pts\n",
    "    ):\n",
    "        # for each predicted bb assignment, check if any target H have a same bb assignment\n",
    "        LUT_event = []\n",
    "        for i, bb_p in enumerate(bb_p_event):\n",
    "            correct = 0\n",
    "            predH_pt = fj_pt_event[bb_p - 10]\n",
    "            for bb_t in bb_t_event:\n",
    "                if bb_p == bb_t + 10:\n",
    "                    correct = 1\n",
    "            LUT_event.append([correct, predH_pt])\n",
    "        LUT.append(LUT_event)\n",
    "    return LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A target look up table is in shape\n",
    "# [event,\n",
    "#    target_H,\n",
    "#        target_bb_assign,\n",
    "#           [retrieved, targetH_pt]]\n",
    "def gen_target_LUT(bb_ps_passed, bb_ts_selected, targetH_pts):\n",
    "    LUT = []\n",
    "    # for each event\n",
    "    for bb_t_event, bb_p_event, targetH_pts_event in zip(\n",
    "        bb_ts_selected, bb_ps_passed, targetH_pts\n",
    "    ):\n",
    "        # for each target fatjet, check if the predictions have a p fatject same with the t fatjet\n",
    "        LUT_event = []\n",
    "        for i, bb_t in enumerate(bb_t_event):\n",
    "            retrieved = 0\n",
    "            targetH_pt = targetH_pts_event[i]\n",
    "            for bb_p in bb_p_event:\n",
    "                if bb_p == bb_t + 10:\n",
    "                    retrieved = 1\n",
    "            LUT_event.append([retrieved, targetH_pt])\n",
    "        LUT.append(LUT_event)\n",
    "    return LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pred/target LUT\n",
    "# each entry corresponds to [recoH correct or not, reco H pt]\n",
    "# or\n",
    "# [targetH retrieved or not, target H pt]\n",
    "def parse_pred_w_target(testfile, predfile, dp_cut=0.5, ap_cut=1 / 13):\n",
    "    # Collect H pt, mask, target and predicted jet and fjets for 3 Hs in each event\n",
    "    # h pt\n",
    "    h1_pt = np.array(testfile[\"TARGETS\"][\"h1\"][\"pt\"])\n",
    "    h2_pt = np.array(testfile[\"TARGETS\"][\"h2\"][\"pt\"])\n",
    "    h3_pt = np.array(testfile[\"TARGETS\"][\"h3\"][\"pt\"])\n",
    "\n",
    "    bh1_pt = np.array(testfile[\"TARGETS\"][\"bh1\"][\"pt\"])\n",
    "    bh2_pt = np.array(testfile[\"TARGETS\"][\"bh2\"][\"pt\"])\n",
    "    bh3_pt = np.array(testfile[\"TARGETS\"][\"bh3\"][\"pt\"])\n",
    "\n",
    "    # mask\n",
    "    h1_mask = np.array(testfile[\"TARGETS\"][\"h1\"][\"mask\"])\n",
    "    h2_mask = np.array(testfile[\"TARGETS\"][\"h2\"][\"mask\"])\n",
    "    h3_mask = np.array(testfile[\"TARGETS\"][\"h3\"][\"mask\"])\n",
    "\n",
    "    bh1_mask = np.array(testfile[\"TARGETS\"][\"bh1\"][\"mask\"])\n",
    "    bh2_mask = np.array(testfile[\"TARGETS\"][\"bh2\"][\"mask\"])\n",
    "    bh3_mask = np.array(testfile[\"TARGETS\"][\"bh3\"][\"mask\"])\n",
    "\n",
    "    # target jet/fjets\n",
    "    b1_h1_t = np.array(testfile[\"TARGETS\"][\"h1\"][\"b1\"])\n",
    "    b1_h2_t = np.array(testfile[\"TARGETS\"][\"h2\"][\"b1\"])\n",
    "    b1_h3_t = np.array(testfile[\"TARGETS\"][\"h3\"][\"b1\"])\n",
    "\n",
    "    b2_h1_t = np.array(testfile[\"TARGETS\"][\"h1\"][\"b2\"])\n",
    "    b2_h2_t = np.array(testfile[\"TARGETS\"][\"h2\"][\"b2\"])\n",
    "    b2_h3_t = np.array(testfile[\"TARGETS\"][\"h3\"][\"b2\"])\n",
    "\n",
    "    bb_bh1_t = np.array(testfile[\"TARGETS\"][\"bh1\"][\"bb\"])\n",
    "    bb_bh2_t = np.array(testfile[\"TARGETS\"][\"bh2\"][\"bb\"])\n",
    "    bb_bh3_t = np.array(testfile[\"TARGETS\"][\"bh3\"][\"bb\"])\n",
    "\n",
    "    # pred jet/fjets\n",
    "    bb_bh1_p = np.array(predfile[\"TARGETS\"][\"bh1\"][\"bb\"])\n",
    "    bb_bh2_p = np.array(predfile[\"TARGETS\"][\"bh2\"][\"bb\"])\n",
    "    bb_bh3_p = np.array(predfile[\"TARGETS\"][\"bh3\"][\"bb\"])\n",
    "\n",
    "    # fatjet detection probability\n",
    "    dp_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"][\"detection_probability\"])\n",
    "    dp_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"][\"detection_probability\"])\n",
    "    dp_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"][\"detection_probability\"])\n",
    "\n",
    "    # fatjet assignment probability\n",
    "    ap_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"][\"assignment_probability\"])\n",
    "    ap_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"][\"assignment_probability\"])\n",
    "    ap_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"][\"assignment_probability\"])\n",
    "\n",
    "    # collect fatjet pt\n",
    "    fj_pts = np.array(testfile[\"INPUTS\"][\"BoostedJets\"][\"fj_pt\"])\n",
    "\n",
    "    # convert some arrays to ak array\n",
    "    dps = np.concatenate(\n",
    "        (dp_bh1.reshape(-1, 1), dp_bh2.reshape(-1, 1), dp_bh3.reshape(-1, 1)), axis=1\n",
    "    )\n",
    "    dps = ak.Array(dps)\n",
    "    aps = np.concatenate(\n",
    "        (ap_bh1.reshape(-1, 1), ap_bh2.reshape(-1, 1), ap_bh3.reshape(-1, 1)), axis=1\n",
    "    )\n",
    "    aps = ak.Array(aps)\n",
    "    bb_ps = np.concatenate(\n",
    "        (bb_bh1_p.reshape(-1, 1), bb_bh2_p.reshape(-1, 1), bb_bh3_p.reshape(-1, 1)),\n",
    "        axis=1,\n",
    "    )\n",
    "    bb_ps = ak.Array(bb_ps)\n",
    "    bb_ts = np.concatenate(\n",
    "        (bb_bh1_t.reshape(-1, 1), bb_bh2_t.reshape(-1, 1), bb_bh3_t.reshape(-1, 1)),\n",
    "        axis=1,\n",
    "    )\n",
    "    bb_ts = ak.Array(bb_ts)\n",
    "    fj_pts = ak.Array(fj_pts)\n",
    "    bh_masks = np.concatenate(\n",
    "        (bh1_mask.reshape(-1, 1), bh2_mask.reshape(-1, 1), bh3_mask.reshape(-1, 1)),\n",
    "        axis=1,\n",
    "    )\n",
    "    bh_masks = ak.Array(bh_masks)\n",
    "    bh_pts = np.concatenate(\n",
    "        (bh1_pt.reshape(-1, 1), bh2_pt.reshape(-1, 1), bh3_pt.reshape(-1, 1)), axis=1\n",
    "    )\n",
    "    bh_pts = ak.Array(bh_pts)\n",
    "\n",
    "    # select predictions and targets\n",
    "    bb_ts_selected, targetH_selected_pts = sel_target_by_mask(bb_ts, bh_pts, bh_masks)\n",
    "    bb_ps_selected = sel_pred_by_dp_ap(dps, aps, bb_ps, dp_cut, ap_cut)\n",
    "\n",
    "    # generate correct/retrieved LUT for pred/target respectively\n",
    "    LUT_pred = gen_pred_LUT(bb_ps_selected, bb_ts_selected, fj_pts)\n",
    "    LUT_target = gen_target_LUT(bb_ps_selected, bb_ts_selected, targetH_selected_pts)\n",
    "\n",
    "    return LUT_pred, LUT_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_pred_spanet, LUT_target_spanet = parse_pred_w_target(test_h5, s_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce282903",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_pred_baseline, LUT_target_baseline = parse_pred_w_target(test_h5, b_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e49987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate efficiency\n",
    "# if bins=None, put all data in a single bin\n",
    "def calc_eff(LUT_pred, bins):\n",
    "    predHs = [predH for event in LUT_pred for predH in event]\n",
    "    predHs = np.array(predHs)\n",
    "\n",
    "    predHs_inds = np.digitize(predHs[:, 1], bins)\n",
    "\n",
    "    correctTruth_per_bin = []\n",
    "    for bin_i in range(1, len(bins)):\n",
    "        correctTruth_per_bin.append(predHs[:, 0][predHs_inds == bin_i])\n",
    "    correctTruth_per_bin = ak.Array(correctTruth_per_bin)\n",
    "\n",
    "    means = ak.mean(correctTruth_per_bin, axis=-1)\n",
    "\n",
    "    errs = np.abs(\n",
    "        clopper_pearson_interval(\n",
    "            num=ak.sum(correctTruth_per_bin, axis=-1),\n",
    "            denom=ak.num(correctTruth_per_bin, axis=-1),\n",
    "        )\n",
    "        - means\n",
    "    )\n",
    "\n",
    "    return means, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate purity\n",
    "def calc_pur(LUT_target, bins):\n",
    "    targetHs = [targetH for event in LUT_target for targetH in event]\n",
    "    targetHs = np.array(targetHs)\n",
    "\n",
    "    targetHs_inds = np.digitize(targetHs[:, 1], bins)\n",
    "\n",
    "    correctTruth_per_bin = []\n",
    "    for bin_i in range(1, len(bins)):\n",
    "        correctTruth_per_bin.append(targetHs[:, 0][targetHs_inds == bin_i])\n",
    "    correctTruth_per_bin = ak.Array(correctTruth_per_bin)\n",
    "\n",
    "    means = ak.mean(correctTruth_per_bin, axis=-1)\n",
    "\n",
    "    errs = np.abs(\n",
    "        clopper_pearson_interval(\n",
    "            num=ak.sum(correctTruth_per_bin, axis=-1),\n",
    "            denom=ak.num(correctTruth_per_bin, axis=-1),\n",
    "        )\n",
    "        - means\n",
    "    )\n",
    "\n",
    "    return means, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2944545",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(200, 1000, 100)\n",
    "bin_centers = [(bins[i] + bins[i + 1]) / 2 for i in range(bins.size - 1)]\n",
    "xerr = (bins[1] - bins[0]) / 2 * np.ones(bins.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_cut = 0.85\n",
    "LUT_pred_spanet, LUT_target_spanet = parse_pred_w_target(test_h5, s_h5, dp_cut=dp_cut)\n",
    "LUT_pred_baseline, LUT_target_baseline = parse_pred_w_target(\n",
    "    test_h5, b_h5, dp_cut=dp_cut\n",
    ")\n",
    "eff_s, efferr_s = calc_eff(LUT_pred_spanet, bins)\n",
    "eff_b, efferr_b = calc_eff(LUT_pred_baseline, bins)\n",
    "pur_s, purerr_s = calc_pur(LUT_target_spanet, bins)\n",
    "pur_b, purerr_b = calc_pur(LUT_target_baseline, bins)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].errorbar(\n",
    "    x=bin_centers, y=eff_s, yerr=efferr_s, fmt=\"o\", capsize=5, label=\"SPANet\"\n",
    ")\n",
    "ax[0].errorbar(\n",
    "    x=bin_centers, y=eff_b, yerr=efferr_b, fmt=\"x\", capsize=5, label=\"Baseline\"\n",
    ")\n",
    "ax[0].set(xlabel=r\"Reconstructed H $p_T$ [GeV]\", ylabel=r\"Matching purity\")\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].set_xlim(300, 900)\n",
    "\n",
    "ax[1].errorbar(\n",
    "    x=bin_centers, y=pur_s, yerr=purerr_s, fmt=\"o\", capsize=5, label=\"SPANet\"\n",
    ")\n",
    "ax[1].errorbar(\n",
    "    x=bin_centers, y=pur_b, yerr=purerr_b, fmt=\"x\", capsize=5, label=\"Baseline\"\n",
    ")\n",
    "ax[1].set(xlabel=r\"True H $p_T$ [GeV]\", ylabel=r\"Matching efficiency\")\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].set_xlim(300, 900)\n",
    "\n",
    "\n",
    "ax[0].legend()\n",
    "# ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spanet_baseline_pur_eff.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
