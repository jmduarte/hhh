{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f819cb",
   "metadata": {},
   "source": [
    "Side note: we are evaluating particle level information\n",
    "maybe we should also do the event level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba38b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billyli/miniforge_x86_new/lib/python3.9/site-packages/coffea/util.py:154: FutureWarning: In coffea version v0.8.0 (target date: 31 Dec 2022), this will be an error.\n",
      "(Set coffea.deprecations_as_errors = True to get a stack trace now.)\n",
      "ImportError: coffea.hist is deprecated\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numba as nb\n",
    "\n",
    "import awkward as ak\n",
    "import click\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import vector\n",
    "\n",
    "from coffea.hist.plot import clopper_pearson_interval\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from src.data.cms.convert_to_h5 import MIN_JETS, N_JETS, N_FJETS\n",
    "\n",
    "vector.register_awkward()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11586b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test target file\n",
    "test_file = \"//Users/billyli/UCSD/hhh/reports/bv2/hhh_test.h5\"\n",
    "test_h5 = h5.File(test_file)\n",
    "\n",
    "# read spanet prediction\n",
    "spanet_file = \"//Users/billyli/UCSD/hhh/reports/bv2/resolved_pred_v29.h5\"\n",
    "s_h5 = h5.File(spanet_file)\n",
    "\n",
    "# read baseline prediction\n",
    "baseline_file = \"//Users/billyli/UCSD/hhh/reports/bv2/pred_baseline.h5\"\n",
    "b_h5 = h5.File(baseline_file)\n",
    "\n",
    "# read spanet prediction\n",
    "pb_off_file = \"//Users/billyli/UCSD/hhh/reports/bv2/bi_input_v1.h5\"\n",
    "pb_h5 = h5.File(pb_off_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6167b0",
   "metadata": {},
   "source": [
    "### Reco Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dee6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_pred_bH_by_dp(dps, aps, bb_ps, dp_cut, ap_cut=1/(13*13)):\n",
    "    # parse predicted bb assignment by DP\n",
    "    dp_filter = dps>dp_cut\n",
    "    ap_filter = aps>ap_cut\n",
    "    ak8_filter = bb_ps>9\n",
    "    filter = dp_filter&ak8_filter\n",
    "    \n",
    "    bb_ps_passed = bb_ps.mask[filter]\n",
    "    bb_ps_passed = ak.drop_none(bb_ps_passed)\n",
    "    \n",
    "    return bb_ps_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a6c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_target_bH_by_mask(bb_ts, bh_pts, bh_masks):\n",
    "    bb_ts_selected = bb_ts.mask[bh_masks]\n",
    "    bb_ts_selected = ak.drop_none(bb_ts_selected)\n",
    "    \n",
    "    bh_selected_pts = bh_pts.mask[bh_masks]\n",
    "    bh_selected_pts = ak.drop_none(bh_selected_pts)\n",
    "    \n",
    "    return bb_ts_selected, bh_selected_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1c2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pred look up table is in shape\n",
    "# [event,\n",
    "#    pred_H, \n",
    "#       [correct, pred_H_pt]]\n",
    "def gen_pred_bH_LUT(bb_ps_passed, bb_ts_selected, fj_pts):\n",
    "    LUT = []\n",
    "    # for each event\n",
    "    for bb_t_event, bb_p_event, fj_pt_event in zip(bb_ts_selected, bb_ps_passed, fj_pts):\n",
    "        # for each predicted bb assignment, check if any target H have a same bb assignment\n",
    "        LUT_event = []\n",
    "        for i, bb_p in enumerate(bb_p_event):\n",
    "            correct = 0\n",
    "            predH_pt = fj_pt_event[bb_p-10]\n",
    "            for bb_t in bb_t_event:\n",
    "                if bb_p == bb_t+10:\n",
    "                    correct = 1\n",
    "            LUT_event.append([correct, predH_pt])\n",
    "        LUT.append(LUT_event)\n",
    "    return LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f497215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A target look up table is in shape\n",
    "# [event,\n",
    "#    target_H, \n",
    "#        target_bb_assign,\n",
    "#           [retrieved, targetH_pt]]\n",
    "def gen_target_bH_LUT(bb_ps_passed, bb_ts_selected, targetH_pts):\n",
    "    LUT = []\n",
    "    # for each event\n",
    "    for bb_t_event, bb_p_event, targetH_pts_event in zip(bb_ts_selected, bb_ps_passed, targetH_pts):\n",
    "        # for each target fatjet, check if the predictions have a p fatject same with the t fatjet\n",
    "        LUT_event = []\n",
    "        for i, bb_t in enumerate(bb_t_event):\n",
    "            retrieved = 0\n",
    "            targetH_pt = targetH_pts_event[i]\n",
    "            for bb_p in bb_p_event:\n",
    "                if bb_p == bb_t+10:\n",
    "                    retrieved = 1\n",
    "            LUT_event.append([retrieved, targetH_pt])\n",
    "        LUT.append(LUT_event)\n",
    "    return LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4c78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pred/target LUT\n",
    "# each entry corresponds to [recoH correct or not, reco H pt]\n",
    "# or \n",
    "# [targetH retrieved or not, target H pt]\n",
    "def parse_boosted_w_target(testfile, predfile, dp_cut=0.8):\n",
    "    # Collect H pt, mask, target and predicted jet and fjets for 3 Hs in each event\n",
    "    # h pt\n",
    "    bh1_pt = np.array(testfile['TARGETS']['bh1']['pt'])\n",
    "    bh2_pt = np.array(testfile['TARGETS']['bh2']['pt'])\n",
    "    bh3_pt = np.array(testfile['TARGETS']['bh3']['pt'])\n",
    "\n",
    "    # mask\n",
    "    bh1_mask = np.array(testfile['TARGETS']['bh1']['mask'])\n",
    "    bh2_mask = np.array(testfile['TARGETS']['bh2']['mask'])\n",
    "    bh3_mask = np.array(testfile['TARGETS']['bh3']['mask'])\n",
    "\n",
    "    # target assignment\n",
    "    bb_bh1_t = np.array(testfile[\"TARGETS\"][\"bh1\"]['bb'])\n",
    "    bb_bh2_t = np.array(testfile[\"TARGETS\"][\"bh2\"]['bb'])\n",
    "    bb_bh3_t = np.array(testfile[\"TARGETS\"][\"bh3\"]['bb'])\n",
    "\n",
    "    try:\n",
    "        # pred assignment\n",
    "        bb_bh1_p = np.array(predfile[\"TARGETS\"][\"bh1\"]['bb'])\n",
    "        bb_bh2_p = np.array(predfile[\"TARGETS\"][\"bh2\"]['bb'])\n",
    "        bb_bh3_p = np.array(predfile[\"TARGETS\"][\"bh3\"]['bb'])\n",
    "    \n",
    "        # boosted Higgs detection probability\n",
    "        dp_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"]['detection_probability'])\n",
    "        dp_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"]['detection_probability'])\n",
    "        dp_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"]['detection_probability'])\n",
    "\n",
    "        # fatjet assignment probability\n",
    "        ap_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"]['assignment_probability'])\n",
    "        ap_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"]['assignment_probability'])\n",
    "        ap_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"]['assignment_probability'])\n",
    "    except:\n",
    "        # pred assignment\n",
    "        bb_bh1_p = np.array(predfile[\"TARGETS\"][\"bh1\"]['bb'])+10\n",
    "        bb_bh2_p = np.array(predfile[\"TARGETS\"][\"bh2\"]['bb'])+10\n",
    "        bb_bh3_p = np.array(predfile[\"TARGETS\"][\"bh3\"]['bb'])+10\n",
    "    \n",
    "         # boosted Higgs detection probability\n",
    "        dp_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"]['mask']).astype('float')\n",
    "        dp_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"]['mask']).astype('float')\n",
    "        dp_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"]['mask']).astype('float')\n",
    "\n",
    "        # fatjet assignment probability\n",
    "        ap_bh1 = np.array(predfile[\"TARGETS\"][\"bh1\"]['mask']).astype('float')\n",
    "        ap_bh2 = np.array(predfile[\"TARGETS\"][\"bh2\"]['mask']).astype('float')\n",
    "        ap_bh3 = np.array(predfile[\"TARGETS\"][\"bh3\"]['mask']).astype('float')\n",
    "    \n",
    "    # collect fatjet pt\n",
    "    fj_pt = np.array(testfile['INPUTS']['BoostedJets']['fj_pt'])\n",
    "    \n",
    "    # convert some arrays to ak array\n",
    "    dps = np.concatenate((dp_bh1.reshape(-1, 1), dp_bh2.reshape(-1, 1), dp_bh3.reshape(-1, 1)), axis=1)\n",
    "    dps = ak.Array(dps)\n",
    "    aps = np.concatenate((ap_bh1.reshape(-1, 1), ap_bh2.reshape(-1, 1), ap_bh3.reshape(-1, 1)), axis=1)\n",
    "    aps = ak.Array(aps)\n",
    "    bb_ps = np.concatenate((bb_bh1_p.reshape(-1, 1), bb_bh2_p.reshape(-1, 1), bb_bh3_p.reshape(-1, 1)), axis=1)\n",
    "    bb_ps = ak.Array(bb_ps)\n",
    "    bb_ts = np.concatenate((bb_bh1_t.reshape(-1, 1), bb_bh2_t.reshape(-1, 1), bb_bh3_t.reshape(-1, 1)), axis=1)\n",
    "    bb_ts = ak.Array(bb_ts)\n",
    "    fj_pt = ak.Array(fj_pt)\n",
    "    bh_masks = np.concatenate((bh1_mask.reshape(-1, 1), bh2_mask.reshape(-1, 1), bh3_mask.reshape(-1, 1)), axis=1)\n",
    "    bh_masks = ak.Array(bh_masks)\n",
    "    bh_pts = np.concatenate((bh1_pt.reshape(-1, 1), bh2_pt.reshape(-1, 1), bh3_pt.reshape(-1, 1)), axis=1)\n",
    "    bh_pts = ak.Array(bh_pts)\n",
    "    \n",
    "    # select predictions and targets\n",
    "    bb_ts_selected, targetH_selected_pts = sel_target_bH_by_mask(bb_ts, bh_pts, bh_masks)\n",
    "    bb_ps_selected = sel_pred_bH_by_dp(dps, aps, bb_ps, dp_cut)\n",
    "    \n",
    "    # generate correct/retrieved LUT for pred/target respectively\n",
    "    LUT_pred = gen_pred_bH_LUT(bb_ps_selected, bb_ts_selected, fj_pt)\n",
    "    LUT_target = gen_target_bH_LUT(bb_ps_selected, bb_ts_selected, targetH_selected_pts)\n",
    "    \n",
    "    # reconstruct bH to remove overlapped ak4 jets\n",
    "    fj_eta = np.array(testfile['INPUTS']['BoostedJets']['fj_eta'])\n",
    "    fj_phi = np.array(testfile['INPUTS']['BoostedJets']['fj_phi'])\n",
    "    fj_mass = np.array(testfile['INPUTS']['BoostedJets']['fj_mass'])\n",
    "    \n",
    "    fjs = ak.zip(\n",
    "        {\n",
    "            \"pt\": fj_pt,\n",
    "            \"eta\": fj_eta,\n",
    "            \"phi\": fj_phi,\n",
    "            \"mass\": fj_mass,\n",
    "        },\n",
    "        with_name=\"Momentum4D\"\n",
    "    )\n",
    "    fj_reco = fjs[bb_ps_selected-10]\n",
    "    \n",
    "    return LUT_pred, LUT_target, fj_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52eadffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unoverlapped_jet_index(fjs, js, dR_min=0.8):\n",
    "    overlapped = ak.sum(js[:, np.newaxis].deltaR(fjs)<dR_min, axis=-2)>0\n",
    "    jet_index_passed = ak.local_index(js).mask[~overlapped]\n",
    "    jet_index_passed = ak.drop_none(jet_index_passed)\n",
    "    return jet_index_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3896b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_pred_h_by_dp(dps, aps, b1_ps, b2_ps, dp_cut=0.0, ap_cut=0):\n",
    "    # parse predicted bb assignment by DP\n",
    "    dp_filter = dps > dp_cut\n",
    "    ap_filter = aps > ap_cut\n",
    "    b1_ak4_filter = b1_ps<10\n",
    "    b2_ak4_filter = b2_ps<10\n",
    "    filter = dp_filter & ap_filter & b1_ak4_filter & b2_ak4_filter\n",
    "    \n",
    "    b1_ps_passed = b1_ps.mask[filter]\n",
    "    b1_ps_passed = ak.drop_none(b1_ps_passed)\n",
    "    \n",
    "    b2_ps_passed = b2_ps.mask[filter]\n",
    "    b2_ps_passed = ak.drop_none(b2_ps_passed)\n",
    "    \n",
    "    return b1_ps_passed, b2_ps_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bcac1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_target_h_by_mask(b1_ts, b2_ts, h_pts, bi_cat_H, h_masks):\n",
    "    b1_ts_selected = b1_ts.mask[h_masks]\n",
    "    b1_ts_selected = ak.drop_none(b1_ts_selected)\n",
    "    \n",
    "    b2_ts_selected = b2_ts.mask[h_masks]\n",
    "    b2_ts_selected = ak.drop_none(b2_ts_selected)\n",
    "    \n",
    "    h_selected_pts = h_pts.mask[h_masks]\n",
    "    h_selected_pts = ak.drop_none(h_selected_pts)\n",
    "    \n",
    "    bi_cat_H_passed = bi_cat_H.mask[h_masks]\n",
    "    bi_cat_H_passed = ak.drop_none(bi_cat_H_passed)\n",
    "    \n",
    "    return b1_ts_selected, b2_ts_selected, h_selected_pts, bi_cat_H_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b54c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pred look up table is in shape\n",
    "# [event,\n",
    "#    pred_H, \n",
    "#       [correct_or_not, pt, overlap_w_H_reco, has_boost_H_target, which_H_target]]\n",
    "@nb.njit\n",
    "def gen_pred_h_LUT(b1_ps_passed, b2_ps_passed, b1_ts_selected, b2_ts_selected, js, goodJetIdx, bi_cat_H_selected, builder):\n",
    "    # for each event\n",
    "    for b1_ps_e, b2_ps_e, b1_ts_e, b2_ts_e, jets_e, goodJetIdx_e, bi_cat_H_e in zip(b1_ps_passed, b2_ps_passed, b1_ts_selected, b2_ts_selected, js, goodJetIdx, bi_cat_H_selected):\n",
    "        # for each predicted bb assignment, check if any target H have a same bb assignment\n",
    "        builder.begin_list()\n",
    "        for b1_p, b2_p in zip(b1_ps_e, b2_ps_e):\n",
    "            if (b1_p in goodJetIdx_e) and (b2_p in goodJetIdx_e):\n",
    "                overlap = 0\n",
    "            else:\n",
    "                overlap = 1\n",
    "            correct = 0\n",
    "            has_t_bH = -1\n",
    "            bH = -1\n",
    "            \n",
    "            predH_pt = (jets_e[b1_p]+jets_e[b2_p]).pt\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            for i, (b1_t, b2_t, bi_cat_H) in enumerate(zip(b1_ts_e, b2_ts_e, bi_cat_H_e)):\n",
    "                if set((b1_p, b2_p)) == set((b1_t, b2_t)):\n",
    "                    correct = 1\n",
    "                    has_t_bH = bi_cat_H\n",
    "                    bH = i\n",
    "                    \n",
    "            builder.begin_list()\n",
    "            builder.append(correct)\n",
    "            builder.append(predH_pt)\n",
    "            builder.append(overlap)\n",
    "            builder.append(has_t_bH)\n",
    "            builder.append(bH)\n",
    "            builder.append(b1_p)\n",
    "            builder.append(b2_p)\n",
    "            builder.end_list()\n",
    "        \n",
    "        builder.end_list()\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a62113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A target look up table is in shape\n",
    "# [event,\n",
    "#    target_H, \n",
    "#        target_bb_assign,\n",
    "#           [retrieved, targetH_pt, can_boost_reco]]\n",
    "@nb.njit\n",
    "def gen_target_h_LUT(b1_ps_passed, b2_ps_passed, b1_ts_selected, b2_ts_selected, targetH_pts, bi_cat_H_selected, builder):\n",
    "    # for each event\n",
    "    for b1_ps_e, b2_ps_e, b1_ts_e, b2_ts_e, tH_pts_e, bi_cat_H_e in zip(b1_ps_passed, b2_ps_passed, b1_ts_selected, b2_ts_selected, targetH_pts, bi_cat_H_selected):\n",
    "        # for each target fatjet, check if the predictions have a p fatject same with the t fatjet\n",
    "        builder.begin_list()\n",
    "        for b1_t, b2_t, tH_pt, bi_cat_H in zip(b1_ts_e, b2_ts_e, tH_pts_e, bi_cat_H_e):\n",
    "            retrieved = 0\n",
    "            can_boost_reco = bi_cat_H\n",
    "            for b1_p, b2_p in zip(b1_ps_e, b2_ps_e):\n",
    "                if set((b1_p, b2_p)) == set((b1_t, b2_t)):\n",
    "                    retrieved = 1\n",
    "            builder.begin_list()\n",
    "            builder.append(retrieved)\n",
    "            builder.append(tH_pt)\n",
    "            builder.append(can_boost_reco)\n",
    "            builder.end_list()\n",
    "        \n",
    "        builder.end_list()\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135e1e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resolved_w_target(testfile, predfile, dp_cut=0.5, fjs_reco=None):\n",
    "    # h pt\n",
    "    h1_pt = np.array(testfile['TARGETS']['h1']['pt'])\n",
    "    h2_pt = np.array(testfile['TARGETS']['h2']['pt'])\n",
    "    h3_pt = np.array(testfile['TARGETS']['h3']['pt'])\n",
    "    \n",
    "    # resolved mask\n",
    "    h1_mask = np.array(testfile['TARGETS']['h1']['mask'])\n",
    "    h2_mask = np.array(testfile['TARGETS']['h2']['mask'])\n",
    "    h3_mask = np.array(testfile['TARGETS']['h3']['mask'])\n",
    "    \n",
    "    h_masks = np.concatenate((h1_mask.reshape(-1, 1), h2_mask.reshape(-1, 1), h3_mask.reshape(-1, 1)), axis=1)\n",
    "    # h_masks = h_masks.astype(float)\n",
    "    # h_masks = ak.Array(h_masks)\n",
    "    \n",
    "    # boosted mask\n",
    "    bh1_mask = np.array(testfile['TARGETS']['bh1']['mask'])\n",
    "    bh2_mask = np.array(testfile['TARGETS']['bh2']['mask'])\n",
    "    bh3_mask = np.array(testfile['TARGETS']['bh3']['mask'])\n",
    "    \n",
    "    bh_masks = np.concatenate((bh1_mask.reshape(-1, 1), bh2_mask.reshape(-1, 1), bh3_mask.reshape(-1, 1)), axis=1)\n",
    "    # bh_masks = bh_masks.astype(float)\n",
    "    # bh_masks = ak.Array(bh_masks)\n",
    "    \n",
    "    # findout which resolved higgs also have boosted reco\n",
    "    bi_cat_H = h_masks & bh_masks\n",
    "    bi_cat_H = bi_cat_H.astype(float)\n",
    "    bi_cat_H = ak.Array(bi_cat_H)\n",
    "    \n",
    "    \n",
    "    # target assignments\n",
    "    b1_h1_t = np.array(testfile[\"TARGETS\"][\"h1\"]['b1']).astype('int')\n",
    "    b1_h2_t = np.array(testfile[\"TARGETS\"][\"h2\"]['b1']).astype('int')\n",
    "    b1_h3_t = np.array(testfile[\"TARGETS\"][\"h3\"]['b1']).astype('int')\n",
    "\n",
    "    b2_h1_t = np.array(testfile[\"TARGETS\"][\"h1\"]['b2']).astype('int')\n",
    "    b2_h2_t = np.array(testfile[\"TARGETS\"][\"h2\"]['b2']).astype('int')\n",
    "    b2_h3_t = np.array(testfile[\"TARGETS\"][\"h3\"]['b2']).astype('int')\n",
    "    \n",
    "    # predict assignments\n",
    "    b1_h1_p = np.array(predfile[\"TARGETS\"][\"h1\"]['b1']).astype('int')\n",
    "    b1_h2_p = np.array(predfile[\"TARGETS\"][\"h2\"]['b1']).astype('int')\n",
    "    b1_h3_p = np.array(predfile[\"TARGETS\"][\"h3\"]['b1']).astype('int')\n",
    "\n",
    "    b2_h1_p = np.array(predfile[\"TARGETS\"][\"h1\"]['b2']).astype('int')\n",
    "    b2_h2_p = np.array(predfile[\"TARGETS\"][\"h2\"]['b2']).astype('int')\n",
    "    b2_h3_p = np.array(predfile[\"TARGETS\"][\"h3\"]['b2']).astype('int')\n",
    "    \n",
    "    # resolved Higgs detection probability\n",
    "    dp_h1 = np.array(predfile[\"TARGETS\"][\"h1\"]['detection_probability'])\n",
    "    dp_h2 = np.array(predfile[\"TARGETS\"][\"h2\"]['detection_probability'])\n",
    "    dp_h3 = np.array(predfile[\"TARGETS\"][\"h3\"]['detection_probability'])\n",
    "    \n",
    "    # ak4 jets assignment probability\n",
    "    ap_h1 = np.array(predfile[\"TARGETS\"][\"h1\"]['assignment_probability'])\n",
    "    ap_h2 = np.array(predfile[\"TARGETS\"][\"h2\"]['assignment_probability'])\n",
    "    ap_h3 = np.array(predfile[\"TARGETS\"][\"h3\"]['assignment_probability'])\n",
    "    \n",
    "    # reconstruct jet 4-momentum objects\n",
    "    j_pt = np.array(testfile['INPUTS']['Jets']['pt'])\n",
    "    j_eta = np.array(testfile['INPUTS']['Jets']['eta'])\n",
    "    j_phi = np.array(testfile['INPUTS']['Jets']['phi'])\n",
    "    j_mass = np.array(testfile['INPUTS']['Jets']['mass'])\n",
    "    js = ak.zip(\n",
    "        {\n",
    "            \"pt\": j_pt,\n",
    "            \"eta\": j_eta,\n",
    "            \"phi\": j_phi,\n",
    "            \"mass\": j_mass,\n",
    "        },\n",
    "        with_name=\"Momentum4D\"\n",
    "    )\n",
    "    \n",
    "    # convert some numpy arrays to ak arrays\n",
    "    dps = np.concatenate((dp_h1.reshape(-1, 1), dp_h2.reshape(-1, 1), dp_h3.reshape(-1, 1)), axis=1)\n",
    "    dps = ak.Array(dps)\n",
    "    aps = np.concatenate((ap_h1.reshape(-1, 1), ap_h2.reshape(-1, 1), ap_h3.reshape(-1, 1)), axis=1)\n",
    "    aps = ak.Array(aps)\n",
    "    \n",
    "    b1_ps = np.concatenate((b1_h1_p.reshape(-1, 1), b1_h2_p.reshape(-1, 1), b1_h3_p.reshape(-1, 1)), axis=1)\n",
    "    b1_ps = ak.Array(b1_ps)\n",
    "    b1_ts = np.concatenate((b1_h1_t.reshape(-1, 1), b1_h2_t.reshape(-1, 1), b1_h3_t.reshape(-1, 1)), axis=1)\n",
    "    b1_ts = ak.Array(b1_ts)\n",
    "    b2_ps = np.concatenate((b2_h1_p.reshape(-1, 1), b2_h2_p.reshape(-1, 1), b2_h3_p.reshape(-1, 1)), axis=1)\n",
    "    b2_ps = ak.Array(b2_ps)\n",
    "    b2_ts = np.concatenate((b2_h1_t.reshape(-1, 1), b2_h2_t.reshape(-1, 1), b2_h3_t.reshape(-1, 1)), axis=1)\n",
    "    b2_ts = ak.Array(b2_ts)\n",
    "\n",
    "    \n",
    "    \n",
    "    h_pts = np.concatenate((h1_pt.reshape(-1, 1), h2_pt.reshape(-1, 1), h3_pt.reshape(-1, 1)), axis=1)\n",
    "    h_pts = ak.Array(h_pts)\n",
    "    \n",
    "    # select predictions and targets\n",
    "    b1_ts_selected, b2_ts_selected, targetH_selected_pts, bi_cat_H_selected = sel_target_h_by_mask(b1_ts, b2_ts, h_pts, bi_cat_H, h_masks)\n",
    "    b1_ps_selected, b2_ps_selected = sel_pred_h_by_dp(dps, aps, b1_ps, b2_ps, dp_cut=dp_cut)\n",
    "    \n",
    "    # find jets that are overlapped with reco boosted Higgs\n",
    "    if fjs_reco is None:\n",
    "        goodJetIdx =  ak.local_index(js)\n",
    "    else:\n",
    "        goodJetIdx = get_unoverlapped_jet_index(fjs_reco, js, dR_min=0.4)\n",
    "    \n",
    "    # generate look up tables\n",
    "    LUT_pred = gen_pred_h_LUT(b1_ps_selected, b2_ps_selected, b1_ts_selected, b2_ts_selected, js, goodJetIdx, bi_cat_H_selected, ak.ArrayBuilder()).snapshot()\n",
    "    LUT_target = gen_target_h_LUT(b1_ps_selected, b2_ps_selected, b1_ts_selected, b2_ts_selected, targetH_selected_pts, bi_cat_H_selected, ak.ArrayBuilder()).snapshot()\n",
    "    \n",
    "    \n",
    "    return LUT_pred, LUT_target, goodJetIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bef1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate efficiency\n",
    "# if bins=None, put all data in a single bin\n",
    "def calc_eff(LUT_boosted_pred, LUT_resolved_pred, bins):\n",
    "\n",
    "    predHs = []\n",
    "    \n",
    "    if LUT_boosted_pred is not None:\n",
    "        # boosted H don't need post processing\n",
    "        predHs_boosted = [predH for event in LUT_boosted_pred for predH in event]\n",
    "        predHs += predHs_boosted\n",
    "\n",
    "    if LUT_resolved_pred is not None:\n",
    "        # Remove overlapped resolved H_reco \n",
    "        predHs_resolved = [predH[0:2] for event in LUT_resolved_pred for predH in event if predH[2]==0]\n",
    "        predHs += predHs_resolved\n",
    "        \n",
    "    # then merge into the list with their pT\n",
    "    predHs = np.array(predHs)\n",
    "    \n",
    "    predHs_inds = np.digitize(predHs[:,1], bins)\n",
    "    \n",
    "    correctTruth_per_bin = []\n",
    "    for bin_i in range(1, len(bins)):\n",
    "        correctTruth_per_bin.append(predHs[:,0][predHs_inds==bin_i])\n",
    "    correctTruth_per_bin = ak.Array(correctTruth_per_bin)\n",
    "    \n",
    "    means = ak.mean(correctTruth_per_bin, axis=-1)\n",
    "    \n",
    "    errs = np.abs(\n",
    "    clopper_pearson_interval(num=ak.sum(correctTruth_per_bin, axis=-1),\\\n",
    "                             denom=ak.num(correctTruth_per_bin, axis=-1)) - means\n",
    "    )\n",
    "    \n",
    "    return means, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8b011c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate purity\n",
    "def calc_pur(LUT_boosted_target, LUT_resolved_target, bins):\n",
    "\n",
    "    targetHs = []\n",
    "\n",
    "    if LUT_boosted_target is not None:\n",
    "        # boosted H don't need post processing\n",
    "        targetHs_boosted = [targetH for event in LUT_boosted_target for targetH in event]\n",
    "        targetHs += targetHs_boosted\n",
    "\n",
    "    if LUT_resolved_target is not None:\n",
    "        # only consider resolved target H that doesn't have a boosted reco\n",
    "        targetHs_resolved = [targetH[0:2] for event in LUT_resolved_target for targetH in event if targetH[2]==0]\n",
    "        targetHs += targetHs_resolved\n",
    "\n",
    "    targetHs = np.array(targetHs)\n",
    "\n",
    "    targetHs_inds = np.digitize(targetHs[:,1], bins)\n",
    "    \n",
    "    correctTruth_per_bin = []\n",
    "    for bin_i in range(1, len(bins)):\n",
    "        correctTruth_per_bin.append(targetHs[:,0][targetHs_inds==bin_i])\n",
    "    correctTruth_per_bin = ak.Array(correctTruth_per_bin)\n",
    "    \n",
    "    means = ak.mean(correctTruth_per_bin, axis=-1)\n",
    "    \n",
    "    errs = np.abs(\n",
    "    clopper_pearson_interval(num=ak.sum(correctTruth_per_bin, axis=-1),\\\n",
    "                             denom=ak.num(correctTruth_per_bin, axis=-1)) - means\n",
    "    )\n",
    "    \n",
    "    return means, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ddc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 1000, 50)\n",
    "bin_centers = [(bins[i]+bins[i+1])/2 for i in range(bins.size-1)]\n",
    "xerr=(bins[1]-bins[0])/2*np.ones(bins.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ac25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_cut=0.5\n",
    "# dp_cut\n",
    "# dR_min\n",
    "# bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b613116",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_resolved_pred_spanet, LUT_resolved_target_spanet, _ = parse_resolved_w_target(test_h5, s_h5, dp_cut=0.0, fjs_reco=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25e8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_resolved_pred_pb, LUT_resolved_target_pb, _ = parse_resolved_w_target(test_h5, pb_h5, dp_cut=0.0, fjs_reco=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa74f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT_resolved_pred_base, LUT_resolved_target_base, _ = parse_resolved_w_target(test_h5, b_h5, dp_cut=dp_cut, fjs_reco=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d858d9c-4423-4402-9344-b68dbfb67ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_s, efferr_s = calc_eff(None, LUT_resolved_pred_spanet, bins)\n",
    "pur_s, purerr_s = calc_pur(None, LUT_resolved_target_spanet, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c9a14-b0ac-48e4-a0df-68597915e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_b, efferr_b = calc_eff(None, LUT_resolved_pred_base, bins)\n",
    "pur_b, purerr_b = calc_pur(None, LUT_resolved_target_base, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a359a6-de1e-48f7-8138-05108961187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_pb, efferr_pb = calc_eff(None, LUT_resolved_pred_pb, bins)\n",
    "pur_pb, purerr_pb = calc_pur(None, LUT_resolved_target_pb, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65661bca-ad89-47c1-84f5-91b60ad4a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].errorbar(x=bin_centers, y=eff_b, xerr=xerr, yerr=efferr_b, fmt='o', capsize=5, label='Baseline')\n",
    "ax[0].errorbar(x=bin_centers, y=eff_s, xerr=xerr, yerr=efferr_s, fmt='o', capsize=5, label='R input SPANet')\n",
    "ax[0].errorbar(x=bin_centers, y=eff_pb, xerr=xerr, yerr=efferr_pb, fmt='o', capsize=5, label='B+R input SPANet')\n",
    "\n",
    "ax[1].errorbar(x=bin_centers, y=pur_b, xerr=xerr, yerr=purerr_b, fmt='o', capsize=5, label='Baseline')\n",
    "ax[1].errorbar(x=bin_centers, y=pur_s, xerr=xerr, yerr=purerr_s, fmt='o', capsize=5, label='R input SPANet')\n",
    "ax[1].errorbar(x=bin_centers, y=pur_pb, xerr=xerr, yerr=purerr_pb, fmt='o', capsize=5, label='B+R input SPANet')\n",
    "\n",
    "ax[0].set(xlabel=r\"Reco H pT (GeV)\", ylabel=r\"Matching efficiency\", title=f\"Resolve Performance of Resolved Model, DP>{0.0}\")\n",
    "ax[1].set(xlabel=r\"Gen H pT (GeV)\", ylabel=r\"Matching purity\", title=f\"Resolve Performance of Resolved Mode, DP>{0.0}l\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff82094-85ee-4241-ac4e-8a41580d01a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
